{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers=[2,2,2,2], width=64, input_size=224, num_classes=1000):\n",
    "        self.inplanes = width\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, width, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, width, layers[0])\n",
    "        self.layer2 = self._make_layer(block, width*2, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, width*2*2, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, width*2*2*2, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(int(input_size/32), stride=1)\n",
    "        self.fc = nn.Linear(width*2*2*2*block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n)) \n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1) \n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion        \n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(BasicBlock).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[[[ 2.7894e-02, -1.7021e-02, -4.3569e-04,  ...,  1.8623e-02,\n",
      "           -9.4457e-03, -5.5121e-03],\n",
      "          [ 1.9402e-03,  4.5650e-02,  2.1501e-02,  ..., -1.0088e-02,\n",
      "           -3.6418e-02, -1.6672e-02],\n",
      "          [ 3.2209e-03,  2.1722e-05, -3.0574e-02,  ...,  3.0366e-02,\n",
      "            3.5727e-02, -1.8138e-02],\n",
      "          ...,\n",
      "          [-2.1858e-02,  1.4240e-02,  5.2196e-02,  ...,  4.4762e-02,\n",
      "            1.2944e-02,  4.5553e-02],\n",
      "          [ 2.3182e-03, -3.1475e-02, -4.6159e-02,  ...,  2.5597e-02,\n",
      "           -3.1520e-02,  1.3124e-02],\n",
      "          [-2.2564e-02, -1.2094e-02,  2.0749e-02,  ...,  3.2669e-03,\n",
      "            5.3035e-03,  1.7976e-02]],\n",
      "\n",
      "         [[ 4.0566e-03, -2.6230e-02, -1.4026e-02,  ..., -2.7016e-02,\n",
      "            2.7483e-02,  3.4470e-02],\n",
      "          [ 4.1776e-03, -2.7517e-05,  2.2272e-02,  ..., -1.5570e-02,\n",
      "           -9.4500e-03,  1.1312e-02],\n",
      "          [ 1.1205e-02, -1.7614e-02, -8.6449e-03,  ...,  5.9828e-02,\n",
      "            1.2297e-02, -3.9514e-03],\n",
      "          ...,\n",
      "          [-1.8074e-02,  1.8540e-03, -1.8265e-03,  ...,  4.7458e-02,\n",
      "           -1.6044e-02, -4.8341e-03],\n",
      "          [ 2.6816e-02,  5.0306e-03, -1.0477e-02,  ...,  4.3253e-02,\n",
      "            1.8846e-02, -7.0228e-03],\n",
      "          [-6.0038e-03,  2.6280e-03,  1.7177e-02,  ..., -2.4804e-02,\n",
      "            1.4136e-03, -9.4265e-03]],\n",
      "\n",
      "         [[ 8.0680e-03,  1.7934e-03,  1.7910e-02,  ...,  2.3729e-02,\n",
      "            1.2378e-02, -1.0323e-02],\n",
      "          [ 6.1380e-02, -2.8804e-02,  5.5789e-03,  ...,  6.8737e-03,\n",
      "           -3.1158e-02, -3.4802e-02],\n",
      "          [-2.8794e-02, -3.2509e-02, -3.1228e-02,  ...,  1.3174e-02,\n",
      "            1.7383e-02,  1.0402e-02],\n",
      "          ...,\n",
      "          [ 4.9543e-02,  6.6538e-02,  9.0484e-03,  ..., -3.7333e-02,\n",
      "            1.6230e-02, -8.4515e-03],\n",
      "          [-8.4463e-04, -6.2259e-03, -3.5480e-02,  ...,  1.4152e-02,\n",
      "            1.9169e-02, -9.7513e-04],\n",
      "          [ 4.7525e-02, -1.9492e-02, -2.8232e-02,  ..., -5.8213e-02,\n",
      "           -2.1718e-02,  3.7891e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5816e-02, -3.6565e-03, -1.2141e-02,  ..., -4.4308e-02,\n",
      "            1.3641e-02, -4.7963e-02],\n",
      "          [-2.6332e-02,  4.2340e-02,  1.2098e-02,  ...,  1.9551e-02,\n",
      "           -6.6229e-03, -6.7533e-03],\n",
      "          [-2.5244e-03,  9.2228e-03,  9.8585e-03,  ...,  2.1444e-02,\n",
      "           -9.3809e-03,  1.5858e-03],\n",
      "          ...,\n",
      "          [-3.0656e-03, -1.9532e-02,  1.5570e-02,  ...,  4.1872e-02,\n",
      "            1.0367e-02, -2.1926e-02],\n",
      "          [ 3.0116e-02, -5.5892e-02, -1.6914e-02,  ...,  5.2874e-03,\n",
      "           -4.5066e-03, -2.2220e-02],\n",
      "          [ 5.2774e-02, -1.6078e-02,  2.4822e-02,  ...,  1.0722e-02,\n",
      "           -3.0154e-02,  3.0492e-03]],\n",
      "\n",
      "         [[ 2.9959e-03, -7.6464e-03,  9.0031e-03,  ..., -2.1720e-02,\n",
      "            9.6180e-03,  3.8724e-02],\n",
      "          [ 8.2371e-03,  1.4734e-02,  2.8331e-03,  ...,  1.1774e-02,\n",
      "           -1.1228e-02, -2.0097e-02],\n",
      "          [-1.7540e-04, -2.1391e-02, -4.0167e-02,  ...,  9.9962e-03,\n",
      "            5.9835e-04,  2.5279e-02],\n",
      "          ...,\n",
      "          [ 3.4684e-02,  1.1090e-02,  5.9869e-03,  ...,  5.0305e-02,\n",
      "            4.1854e-02,  2.2214e-02],\n",
      "          [-4.3991e-03,  1.8417e-02, -2.0069e-02,  ..., -6.8233e-03,\n",
      "           -3.1448e-02,  5.2956e-02],\n",
      "          [ 7.1133e-04,  2.8245e-02,  3.6840e-02,  ...,  4.6219e-02,\n",
      "            3.7872e-02,  7.9471e-03]],\n",
      "\n",
      "         [[ 4.9654e-03, -9.6010e-03, -1.2043e-02,  ..., -2.0474e-02,\n",
      "           -1.2961e-02, -3.8875e-03],\n",
      "          [-1.8720e-02, -1.5600e-03,  1.7557e-02,  ..., -4.2665e-02,\n",
      "           -1.1265e-02,  1.1104e-02],\n",
      "          [ 1.7953e-02, -8.9238e-03, -1.9332e-02,  ...,  1.6240e-02,\n",
      "           -9.4346e-03,  9.9446e-03],\n",
      "          ...,\n",
      "          [ 4.2138e-02, -1.9976e-02, -1.7053e-02,  ..., -1.1005e-02,\n",
      "           -1.5871e-02,  1.6406e-02],\n",
      "          [-3.7268e-02, -2.1519e-02,  2.5717e-02,  ..., -2.9443e-02,\n",
      "           -3.1582e-02, -8.7647e-03],\n",
      "          [ 1.2859e-02,  1.5991e-02, -1.3464e-02,  ...,  4.9093e-02,\n",
      "           -1.6326e-03,  1.2044e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4339e-03,  3.3971e-02, -1.8290e-02,  ...,  1.3221e-02,\n",
      "           -3.7568e-02,  2.1805e-02],\n",
      "          [-2.0251e-02, -1.4999e-02, -1.0070e-02,  ..., -1.1533e-03,\n",
      "           -1.5696e-02, -1.7588e-02],\n",
      "          [ 4.8109e-02, -1.5514e-02,  2.0000e-02,  ..., -1.0360e-02,\n",
      "            1.0707e-02, -2.7703e-02],\n",
      "          ...,\n",
      "          [ 3.1420e-02, -1.8477e-02, -1.1264e-02,  ..., -2.7850e-02,\n",
      "           -2.5266e-02, -2.4846e-02],\n",
      "          [ 1.8335e-03,  3.7634e-02,  1.5049e-02,  ...,  1.6277e-02,\n",
      "            4.8103e-04, -2.2343e-03],\n",
      "          [ 2.0531e-02,  1.3586e-02,  3.7126e-02,  ...,  6.8048e-02,\n",
      "            6.0879e-03, -1.8125e-02]],\n",
      "\n",
      "         [[-2.7925e-02, -3.0851e-02, -4.5819e-02,  ..., -2.2001e-02,\n",
      "           -3.8518e-02,  1.8756e-03],\n",
      "          [ 1.8304e-02, -2.1968e-03, -3.0380e-02,  ..., -3.9081e-02,\n",
      "           -1.0788e-03, -3.1058e-02],\n",
      "          [-9.6020e-03, -5.4900e-03, -2.5766e-02,  ..., -1.4446e-02,\n",
      "            2.3604e-02,  4.2422e-02],\n",
      "          ...,\n",
      "          [-1.0117e-03,  3.4501e-02,  5.0059e-02,  ..., -4.3252e-03,\n",
      "            1.0109e-02,  4.2708e-02],\n",
      "          [ 4.7141e-03,  4.5186e-02, -3.3501e-04,  ...,  3.3693e-03,\n",
      "            2.2894e-02, -1.0489e-02],\n",
      "          [-9.8389e-03,  2.3000e-03,  1.7433e-02,  ..., -2.3296e-02,\n",
      "           -8.6849e-03, -7.4832e-03]],\n",
      "\n",
      "         [[-9.8312e-03, -3.7073e-02, -2.9821e-02,  ...,  7.2089e-03,\n",
      "           -8.6371e-03,  1.8339e-02],\n",
      "          [ 1.8456e-02, -6.5289e-03,  2.9223e-02,  ..., -2.6426e-02,\n",
      "            1.2603e-02,  8.1190e-03],\n",
      "          [ 6.3570e-03,  3.0092e-02, -1.0243e-02,  ...,  8.1884e-03,\n",
      "            3.0378e-03,  9.1840e-03],\n",
      "          ...,\n",
      "          [-1.1936e-03,  2.8174e-02, -2.7026e-02,  ...,  2.9519e-02,\n",
      "           -3.1477e-02, -1.4732e-02],\n",
      "          [-2.1722e-02,  8.6346e-03,  2.4801e-02,  ...,  8.2868e-04,\n",
      "           -2.2486e-04, -2.8199e-02],\n",
      "          [ 9.7226e-03, -3.0683e-02, -4.4378e-02,  ..., -6.8490e-03,\n",
      "           -7.5468e-03, -2.7314e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.7527e-02, -8.1825e-03,  1.1285e-02,  ..., -3.7661e-02,\n",
      "            1.9418e-03,  2.9666e-02],\n",
      "          [ 3.0475e-03, -3.7253e-02, -5.1647e-02,  ..., -1.4143e-03,\n",
      "           -8.0877e-03,  2.9373e-02],\n",
      "          [-1.7114e-02, -5.6958e-02, -4.7757e-02,  ...,  1.9301e-02,\n",
      "            1.1440e-02, -1.3599e-02],\n",
      "          ...,\n",
      "          [ 5.8992e-03,  1.9647e-02,  1.9225e-02,  ..., -2.4304e-02,\n",
      "            4.8874e-02, -5.5757e-02],\n",
      "          [-1.2439e-03, -3.2995e-02, -1.4242e-02,  ...,  5.7363e-03,\n",
      "           -4.5567e-03, -2.6151e-02],\n",
      "          [ 3.4830e-02,  5.2469e-02,  2.2329e-02,  ..., -9.2678e-03,\n",
      "            3.8134e-02, -2.0702e-02]],\n",
      "\n",
      "         [[ 4.9115e-02,  2.5493e-03,  5.0485e-03,  ..., -3.0341e-03,\n",
      "           -3.5329e-02,  2.1783e-03],\n",
      "          [ 8.9106e-04, -7.5827e-02,  1.5018e-04,  ...,  2.2685e-02,\n",
      "            4.5997e-02, -2.5878e-02],\n",
      "          [ 1.8326e-02, -4.6166e-02, -2.6301e-02,  ...,  2.7762e-03,\n",
      "           -3.7041e-02, -1.4776e-03],\n",
      "          ...,\n",
      "          [ 7.5068e-03, -1.8545e-02,  3.7118e-03,  ..., -3.7461e-02,\n",
      "            1.1192e-02, -1.9454e-02],\n",
      "          [ 2.0325e-03,  1.8517e-02,  3.5738e-02,  ..., -1.2413e-02,\n",
      "            2.7876e-02,  3.2358e-02],\n",
      "          [-3.5751e-02,  3.4807e-03, -1.3804e-02,  ...,  1.7013e-03,\n",
      "            2.2453e-02,  3.2410e-02]],\n",
      "\n",
      "         [[ 1.1695e-02, -1.6404e-02, -2.3655e-02,  ..., -6.6225e-03,\n",
      "            1.1793e-02, -6.2795e-03],\n",
      "          [ 4.2948e-02,  9.0639e-03,  4.2656e-02,  ..., -5.1564e-02,\n",
      "           -5.0642e-02, -3.6158e-02],\n",
      "          [-2.3070e-02,  1.7767e-02,  4.1763e-02,  ...,  3.1007e-02,\n",
      "            2.0251e-02,  8.3802e-03],\n",
      "          ...,\n",
      "          [ 1.8929e-02, -2.4238e-02, -1.6382e-02,  ..., -5.6078e-03,\n",
      "            2.9830e-02, -1.1447e-02],\n",
      "          [-1.1774e-02, -9.0125e-03,  4.2445e-03,  ...,  5.7769e-02,\n",
      "            3.1977e-02, -5.0584e-03],\n",
      "          [ 1.0912e-02,  6.3804e-02, -5.6388e-03,  ..., -3.1202e-02,\n",
      "           -1.1394e-02, -3.3606e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.5141e-02,  3.1133e-02, -1.8451e-02,  ..., -1.0718e-02,\n",
      "            1.5293e-02, -1.5871e-02],\n",
      "          [-1.2795e-02, -5.3067e-03,  4.6615e-03,  ...,  4.2007e-02,\n",
      "           -2.5260e-02, -1.1229e-02],\n",
      "          [ 4.0348e-03, -2.1200e-02, -1.8405e-02,  ...,  3.2749e-02,\n",
      "            3.1282e-02, -1.7988e-02],\n",
      "          ...,\n",
      "          [-4.9328e-03,  7.3847e-03, -9.6810e-03,  ...,  1.2436e-03,\n",
      "           -5.0071e-03,  2.1825e-02],\n",
      "          [ 4.5388e-03,  2.0303e-03,  6.7871e-03,  ...,  4.5459e-03,\n",
      "            3.5415e-02, -4.6731e-02],\n",
      "          [-1.3339e-02, -7.7340e-03, -1.8856e-02,  ...,  1.1184e-02,\n",
      "           -3.2361e-02,  1.5942e-02]],\n",
      "\n",
      "         [[ 5.9227e-03, -1.3189e-02,  6.4496e-03,  ...,  2.5144e-02,\n",
      "           -4.0249e-02, -4.8909e-02],\n",
      "          [ 1.4489e-02,  1.0252e-02,  1.6239e-02,  ...,  1.1648e-02,\n",
      "            1.9587e-02, -2.1833e-02],\n",
      "          [ 2.7711e-02, -1.8316e-02, -3.0845e-02,  ...,  2.9673e-02,\n",
      "            1.8409e-02,  3.2743e-02],\n",
      "          ...,\n",
      "          [-1.4952e-02, -4.4516e-02,  4.6133e-03,  ..., -3.1706e-02,\n",
      "           -5.1792e-03, -3.9542e-02],\n",
      "          [-1.2091e-02, -3.9119e-02,  2.6752e-02,  ..., -2.9062e-02,\n",
      "           -5.9562e-02,  1.9766e-02],\n",
      "          [-1.1016e-02,  8.6099e-03,  6.9310e-03,  ..., -2.3475e-02,\n",
      "           -8.1073e-02, -9.5763e-03]],\n",
      "\n",
      "         [[-7.2916e-03,  2.2262e-02,  1.9920e-03,  ..., -2.4226e-03,\n",
      "            3.2000e-02,  2.9347e-03],\n",
      "          [ 2.3192e-03,  1.1735e-02,  2.0341e-02,  ...,  2.4613e-02,\n",
      "            2.4248e-02, -1.1740e-02],\n",
      "          [-4.0104e-03,  1.3316e-02, -6.8872e-02,  ..., -8.4460e-03,\n",
      "            2.3269e-02,  2.4968e-02],\n",
      "          ...,\n",
      "          [-2.8863e-02, -2.1197e-02,  3.7489e-03,  ..., -3.9607e-02,\n",
      "           -1.1999e-02, -2.0611e-02],\n",
      "          [-5.4929e-03, -1.9817e-02,  1.0105e-02,  ...,  9.7514e-04,\n",
      "           -4.5820e-02,  2.1648e-02],\n",
      "          [-3.7249e-02, -7.0881e-03, -8.1114e-03,  ..., -2.0192e-02,\n",
      "           -3.5977e-02,  7.2064e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 9.2547e-03,  2.1940e-02,  1.2573e-02,  ..., -1.0595e-02,\n",
      "           -3.0469e-02, -1.0464e-03],\n",
      "          [-1.0869e-02,  2.8927e-02,  2.5044e-02,  ...,  1.8892e-02,\n",
      "           -2.8151e-02, -9.2779e-03],\n",
      "          [-2.1846e-02, -2.9626e-02,  3.9739e-02,  ...,  3.5720e-02,\n",
      "            3.0867e-02,  1.0108e-02],\n",
      "          ...,\n",
      "          [ 2.4262e-03, -2.8696e-02,  1.5925e-03,  ..., -2.3401e-03,\n",
      "           -2.4900e-03,  2.9648e-02],\n",
      "          [-3.9059e-02, -4.3064e-02, -3.3105e-03,  ...,  3.4708e-03,\n",
      "           -3.7221e-02,  1.7276e-02],\n",
      "          [-8.4791e-04,  4.2726e-02, -1.1815e-02,  ...,  1.1358e-03,\n",
      "            2.2766e-02,  3.5908e-02]],\n",
      "\n",
      "         [[ 2.0096e-03, -1.5372e-02,  2.0054e-02,  ..., -9.0550e-03,\n",
      "           -5.2337e-03,  1.8621e-02],\n",
      "          [-4.2632e-03,  8.4622e-03,  5.2675e-03,  ..., -1.9522e-02,\n",
      "           -2.7149e-02, -2.4908e-02],\n",
      "          [-1.3837e-02, -1.0099e-02,  3.3945e-02,  ...,  6.1829e-03,\n",
      "            5.5800e-03, -3.2686e-03],\n",
      "          ...,\n",
      "          [ 2.9912e-02, -2.0814e-02,  3.6141e-03,  ..., -1.2005e-02,\n",
      "            5.0073e-02,  3.0485e-03],\n",
      "          [-1.5633e-02,  3.8260e-02, -2.6139e-02,  ..., -3.7588e-02,\n",
      "            1.8947e-02,  2.3086e-02],\n",
      "          [ 7.2265e-03, -5.9356e-03, -2.7334e-02,  ..., -1.6217e-02,\n",
      "           -2.0615e-03,  1.5420e-02]],\n",
      "\n",
      "         [[-2.8280e-02,  1.9033e-02, -3.8867e-02,  ...,  4.6633e-04,\n",
      "           -2.4031e-02,  3.5141e-02],\n",
      "          [ 3.1391e-03,  1.2918e-02, -1.1654e-02,  ...,  1.7134e-03,\n",
      "           -3.7805e-02,  1.7925e-02],\n",
      "          [-9.3939e-03,  4.8693e-03, -2.1140e-02,  ...,  5.7389e-03,\n",
      "            1.3766e-02, -2.6508e-02],\n",
      "          ...,\n",
      "          [ 1.1219e-02, -1.7019e-02,  2.2895e-02,  ...,  2.4320e-03,\n",
      "            1.6064e-03, -1.3992e-02],\n",
      "          [-1.1339e-02, -1.2751e-03,  5.4064e-02,  ...,  2.8018e-02,\n",
      "           -6.7047e-03,  3.9193e-04],\n",
      "          [-2.9493e-02,  1.7762e-02,  1.6196e-02,  ...,  6.9674e-03,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           -2.3281e-02, -2.2445e-02]]]], device='cuda:0', requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "module = model.conv1\n",
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.random_unstructured(module, name=\"weight\", amount=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(BasicBlock)\n",
    "\n",
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),\n",
    "    (model.fc, 'weight'),\n",
    ")\n",
    "\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in conv1.weight: 60.84%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.conv1.weight == 0))\n",
    "        / float(model.conv1.weight.nelement())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in fc.weight: 49.80%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Sparsity in fc.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.fc.weight == 0))\n",
    "        / float(model.fc.weight.nelement())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 50.00%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.fc.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.fc.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "print('==> Building model..')\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['skewed_training', 'validation']:\n",
    "            if phase == 'skewed_training':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'skewed_training'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'skewed_training':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'skewed_training':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'validation' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    str1 = input('Enter depth(number of layers, default: 2 2 2 2): ')\n",
    "    layerlist = str1.split()\n",
    "    layerlist = [int(i) for i in layerlist] \n",
    "\n",
    "    str2 = input('Enter width(number of channels, default: 64 ): ')\n",
    "    width = int(str2)\n",
    "\n",
    "    str3 = input('Enter resolution(input size, default: 224, the number have to be divisible by 32): ')\n",
    "    input_size = int(str3)\n",
    "    \n",
    "    #To determine if your system supports CUDA\n",
    "    print(\"==> Check devices..\")\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(\"Current device: \",device)\n",
    "\n",
    "    #Also can print your current GPU id, and the number of GPUs you can use.\n",
    "    print(\"Our selected device: \", torch.cuda.current_device())\n",
    "    print(torch.cuda.device_count(), \" GPUs is available\")\n",
    "\n",
    "\n",
    "    print('==> Preparing dataset..')\n",
    "\n",
    "    data_transforms = {\n",
    "        'skewed_training': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(input_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'validation': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),    \n",
    "        'evaluation': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    data_dir = 'food11re'\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                              data_transforms[x])\n",
    "                      for x in ['skewed_training','validation','evaluation']}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                                 shuffle=True, num_workers=2)\n",
    "                  for x in ['skewed_training','validation','evaluation']}\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['skewed_training','validation','evaluation']}\n",
    "    class_names = image_datasets['skewed_training'].classes\n",
    "    \n",
    "    model_ft = ResNet(BasicBlock, layerlist, width, input_size, 11)\n",
    "\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "    model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, dataloaders,\n",
    "                           num_epochs=25)\n",
    "\n",
    "\n",
    "    PATH = 'lab1\\lab1_model.pht'\n",
    "    torch.save(model_ft.state_dict(), PATH)\n",
    "\n",
    "\n",
    "    class_correct = list(0. for i in range(11))\n",
    "    class_total = list(0. for i in range(11))\n",
    "    correct_top3 = 0.\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['evaluation']:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model_ft(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            _, predicted_top3 = outputs.topk(3, dim=1, largest=True, sorted=True)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            c_top3_0 = (predicted_top3[:,0] == labels).squeeze()\n",
    "            c_top3_1 = (predicted_top3[:,1] == labels).squeeze()\n",
    "            c_top3_2 = (predicted_top3[:,2] == labels).squeeze()\n",
    "            if(labels.size()==torch.Size([4])):\n",
    "                for i in range(4):\n",
    "                    class_correct[labels[i]] += c[i].item()\n",
    "                    class_total[labels[i]] += 1\n",
    "                    correct_top3 += c_top3_0[i].item()\n",
    "                    correct_top3 += c_top3_1[i].item()\n",
    "                    correct_top3 += c_top3_2[i].item()\n",
    "            else:\n",
    "                for i in range(3):\n",
    "                    class_correct[labels[i]] += c[i].item()\n",
    "                    class_total[labels[i]] += 1\n",
    "                    correct_top3 += c_top3_0[i].item()\n",
    "                    correct_top3 += c_top3_1[i].item()\n",
    "                    correct_top3 += c_top3_2[i].item()\n",
    "\n",
    "    total_correct = 0.\n",
    "    for i in range(11):\n",
    "        total_correct+=class_correct[i]\n",
    "\n",
    "    print('Test set: Top1 Accuracy: %d/%d (%2d %%) , Top3 Accuracy: %d/%d (%2d %%)' % (\n",
    "        total_correct,dataset_sizes['evaluation'], 100 * total_correct / dataset_sizes['evaluation'],\n",
    "        correct_top3,dataset_sizes['evaluation'], 100 * correct_top3 / dataset_sizes['evaluation']))\n",
    "    \n",
    "    for i in range(11):\n",
    "        print('class %s : %d/%d %2d %%' % (\n",
    "            class_names[i],class_correct[i],class_total[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter depth(number of layers, default: 2 2 2 2): 2 3 2 2\n",
      "Enter width(number of channels, default: 64 ): 70\n",
      "Enter resolution(input size, default: 224, the number have to be divisible by 32): 288\n",
      "==> Check devices..\n",
      "Current device:  cuda\n",
      "Our selected device:  0\n",
      "1  GPUs is available\n",
      "==> Preparing dataset..\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系統找不到指定的路徑。: 'food11re\\\\skewed_training'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c7bc734e5e35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-f3dd211c4260>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m     image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n\u001b[0;32m     45\u001b[0m                                               data_transforms[x])\n\u001b[1;32m---> 46\u001b[1;33m                       for x in ['skewed_training','validation','evaluation']}\n\u001b[0m\u001b[0;32m     47\u001b[0m     dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n\u001b[0;32m     48\u001b[0m                                                  shuffle=True, num_workers=2)\n",
      "\u001b[1;32m<ipython-input-14-f3dd211c4260>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     44\u001b[0m     image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n\u001b[0;32m     45\u001b[0m                                               data_transforms[x])\n\u001b[1;32m---> 46\u001b[1;33m                       for x in ['skewed_training','validation','evaluation']}\n\u001b[0m\u001b[0;32m     47\u001b[0m     dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n\u001b[0;32m     48\u001b[0m                                                  shuffle=True, num_workers=2)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    206\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m                                           is_valid_file=is_valid_file)\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m     92\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[0;32m     93\u001b[0m                                             target_transform=target_transform)\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m_find_classes\u001b[1;34m(self, dir)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mNo\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msubdirectory\u001b[0m \u001b[0mof\u001b[0m \u001b[0manother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \"\"\"\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mclass_to_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系統找不到指定的路徑。: 'food11re\\\\skewed_training'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
